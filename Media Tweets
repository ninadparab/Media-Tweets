#Loading Libraries

library(rtweet)
library(tidyverse)
library(lubridate)
library(tidytext)
library(tm)
library(wordcloud)
library(syuzhet)


#Logging On Twitter

create_token(
  app = "#AppName",
  consumer_key = "#ConsumerKey",
  consumer_secret = "#ConsumerSecretKey")


#Getting Tweets from Twitter Handles of news channels
#6 Indian news channels


NDTV <- get_timelines("ndtv", n = 18000)
ZeeNews <- get_timelines("zeenews", n = 18000)
CNNnews18 <- get_timelines("CNNnews18", n = 18000)
Republic <- get_timelines("republic", n = 18000)
TimesNow <- get_timelines("TimesNow", n = 18000)
IndiaToday <- get_timelines("IndiaToday", n = 18000)



#function to get tweets by date

dailytweet <-
  function(channel)
  {
    temp <- channel%>%
      mutate(date = as.Date(created_at))%>%
      group_by(date)%>%
      summarise(count=n())
      
    colnames(temp) <- c("date",deparse(substitute(channel)))
    
    temp
  }


#Plotting daily tweets of all channels

dailytweet(NDTV)%>%
  left_join(dailytweet(Republic), by = c("date"="date"))%>%
  left_join(dailytweet(TimesNow), by = c("date"="date"))%>%
  left_join(dailytweet(ZeeNews), by = c("date"="date"))%>%
  left_join(dailytweet(IndiaToday), by = c("date"="date"))%>%
  left_join(dailytweet(CNNnews18), by = c("date"="date"))%>%
  gather(NDTV:CNNnews18,key="channel", value="count")%>%
  ggplot(aes(x=date,y=count, colour=channel))+
  geom_line()
  
#Function to plot WordCloud based on Hashtags

hashtag <- function(channel)
{
  temp <-
    as.data.frame(table(unlist(channel$hashtags)[!is.na(unlist(channel$hashtags))]))%>%
    arrange(desc(Freq))%>%
    head(20)
  
  wordcloud(temp$Var1,
            temp$Freq, 
            colors=brewer.pal(8, "Dark2"),
            random.order=FALSE, rot.per=0.3,
            scale=c(1,.5))
}


#Plotting WordCloud of hashtags for all channels

hashtag(NDTV)
hashtag(Republic)
hashtag(TimesNow)
hashtag(ZeeNews)
hashtag(IndiaToday)
hashtag(CNNnews18)

  
  

#Function to clean text (from online resource)

clean.text <- function(some_txt)
{
  some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
  some_txt = gsub("@\\w+", "", some_txt)
  some_txt = gsub("[[:punct:]]", "", some_txt)
  some_txt = gsub("[[:digit:]]", "", some_txt)
  some_txt = gsub("http\\w+", "", some_txt)
  some_txt = gsub("[ \t]{2,}", "", some_txt)
  some_txt = gsub("^\\s+|\\s+$", "", some_txt)
  some_txt = gsub("amp", "", some_txt)
  some_txt = tolower(some_txt)
}  


#Function for WordCloud

cloudofwords <-
  function(object)
  {
    clean <- clean.text(object$text)
    corpus <- Corpus(VectorSource(clean))
    corpus <- tm_map(corpus, removeWords, stopwords("english"))
    dtm <- TermDocumentMatrix(corpus)
    
    m <- as.matrix(dtm)
    v <- sort(rowSums(m),decreasing=TRUE)
    d <- data.frame(word = names(v),freq=v)
    
    par(bg="grey30") 
    wordcloud(head(d,25)$word, d$freq, col=terrain.colors(length(d$word), alpha=0.9), random.order=FALSE, rot.per=0.3)
    
  }


#Function for getting Sentiment

sentiment <-
  function(object1)
  {
    object <-
      object1%>%
      filter(date(created_at)>"2018-08-02")
    
    clean <- clean.text(object$text)
    
    d1<-get_nrc_sentiment(clean)
    td<-data.frame(t(d1))
    
    td_new <- data.frame(rowSums(td))
    
    names(td_new)[1] <- "count"
    td_new <- cbind("sentiment" = rownames(td_new), td_new)
    rownames(td_new) <- NULL
    td_new2<-td_new[c(1,3:8),]
    
    td_new2%>%
      ggplot(aes(x=sentiment, y=count,fill=sentiment))+
      geom_bar(stat="identity")+
      ggtitle(deparse(substitute(object1)))
    
  }
  
sentiment(republic)
sentiment(ndtv)
sentiment(BBCWorld)
sentiment(FoxNews)
sentiment(CNN)
sentiment(CNNnews18)
sentiment(zeenews)

cloudofwords(republic)
cloudofwords(ndtv)
cloudofwords(BBCWorld)
cloudofwords(FoxNews)
cloudofwords(CNN)
cloudofwords(CNNnews18)
cloudofwords(zeenews)
